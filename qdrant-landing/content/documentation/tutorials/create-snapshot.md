---
title: Create and restore collections from snapshot
weight: 14
---

# Exporting Qdrant collections into snapshots

| Time: 20 min | Level: Beginner |  |    |
|--------------|-----------------|--|----|

A collection is a basic unit of data storage in Qdrant. It contains vectors, their IDs, and payloads. However, keeping the search efficient requires additional data structures to be built on top of the data. Building these data structures may take a while, especially for large collections. 
That's why using snapshots is the best way to export and import Qdrant collections, as they contain all the bits and pieces required to restore the entire collection efficiently.

This tutorial will show you how to create a snapshot of a collection and restore it. Since working with snapshots in a distributed environment might be thought to be a bit more complex, we will use a 3-node Qdrant cluster. However, the same approach applies to a single-node setup.

<aside role="status">Snapshots cannot be created in local mode of Python SDK. You need to spin up a Qdrant Docker container or use Qdrant Cloud.</aside>

## Prerequisites

Let's assume you already have a running Qdrant instance or a cluster. If not, you can follow the [installation guide](/documentation/guides/installation) to set up a local Qdrant instance or use [Qdrant Cloud](https://cloud.qdrant.io/) to create a cluster in a few clicks.

Once the cluster is running, let's install the required dependencies:

```shell
pip install qdrant-client datasets
```  

### Establish a connection to Qdrant

We are going to use the Python SDK and raw HTTP calls to interact with Qdrant. Since we are going to use a 3-node cluster, we need to know the URLs of all the nodes. For the simplicity, let's keep them all in constants, along with the collection name, so we can refer to them later:

```python
QDRANT_MAIN_URL = "https://my-cluster.eastus-0.azure.cloud.qdrant.io:6333"
QDRANT_API_KEY = "my-api-key"
QDRANT_NODES = (
    "https://node-0-my-cluster.eastus-0.azure.cloud.qdrant.io:6333",
    "https://node-1-my-cluster.eastus-0.azure.cloud.qdrant.io:6333",
    "https://node-2-my-cluster.eastus-0.azure.cloud.qdrant.io:6333",
)
INPUT_COLLECTION_NAME = "test_collection"
```

<aside role="status">If you are using Qdrant Cloud, you can find the URL and API key in the <a href="https://cloud.qdrant.io/">Qdrant Cloud dashboard</a>.</aside>

We can now create a client instance:

```python
from qdrant_client import QdrantClient

client = QdrantClient(QDRANT_MAIN_URL, api_key=QDRANT_API_KEY)
```

First of all, we are going to create a collection from a precomputed dataset. If you already have a collection, you can skip this step and start by [creating a snapshot](#create-a-snapshot).

### Load the dataset

We are going to use a dataset with precomputed embeddings, available on Hugging Face Hub. The dataset is called [Qdrant/arxiv-titles-instructorxl-embeddings](https://huggingface.co/datasets/Qdrant/arxiv-titles-instructorxl-embeddings) and was created using the [InstructorXL](https://huggingface.co/hkunlp/instructor-xl) model. It contains 2.25M embeddings for the titles of the papers from the [arXiv](https://arxiv.org/) dataset.

Loading the dataset is as simple as:

```python
from datasets import load_dataset

dataset = load_dataset(
    "Qdrant/arxiv-titles-instructorxl-embeddings", split="train", streaming=True
)
```

We used the streaming mode, so the dataset is not loaded into memory. Instead, we can iterate through it and extract the id and vector embedding:

```python
for payload in dataset:
    id = payload.pop("id")
    vector = payload.pop("vector")
    print(id, vector, payload)
```

A single payload looks like this:

```json
{
  'title': 'Dynamics of partially localized brane systems', 
  'DOI': '1109.1415'
}
```

### Create a collection

First things first, we need to create our collection. We're not going to play with the configuration of it, but it makes sense do it right now. 
The configuration is also a part of the collection snapshot.

```python
from qdrant_client import models

client.recreate_collection(
    collection_name=INPUT_COLLECTION_NAME,
    vectors_config=models.VectorParams(
        size=768,  # Size of the embedding vector generated by the InstructorXL model
        distance=models.Distance.COSINE
    ),
)
```

### Upload the dataset

While loaded, it is pretty straightforward to upload the collection from the precomputed embeddings. Calculating the embeddings is usually
a bottleneck of the vector search pipelines, but we are happy to have them in place already. Since the goal of this tutorial is to show how to create a snapshot, **we are going to upload only a small part of the dataset**.

```python
ids, vectors, payloads = [], [], []
for payload in dataset:
    id = payload.pop("id")
    vector = payload.pop("vector")
    
    ids.append(id)
    vectors.append(vector)
    payloads.append(payload)
    
    if len(ids) == 1000:
        break

client.upsert(
    collection_name=INPUT_COLLECTION_NAME,
    points=models.Batch(
        ids=ids,
        vectors=vectors,
        payloads=payloads,
    ),
)
```

## Create a snapshot

Qdrant exposes HTTP endpoint to request creating a snapshot, but we can also call it with the Python SDK. Creating a snapshot may take a while. If you encounter any timeout, that doesn't mean the process is not running.

```python
snapshot_info = client.create_snapshot(collection_name=collection_name)
print(snapshot_info)
```

<aside role="status">You may get a timeout error. The process is still running, but creating a snapshot may take a while.</aside>

As a response, we should see a similar output:

```python
name='LAION-5B-1217055918586176-2023-07-04-11-51-24.snapshot' creation_time='2023-07-04T11:51:25' size=74202112
```

## List all snapshots
You can always check what are the snapshots available for a particular collection.

```python
snapshots = client.list_snapshots(collection_name=dataset_name)
print(snapshots)
```

This endpoint exposes all the snapshots in the same format as before:

```python
[
    SnapshotDescription(
        name="LAION-5B-1217055918586176-2023-07-04-11-51-24.snapshot",
        creation_time="2023-07-04T11:51:25",
        size=74202112,
    )
]
```

We can use the same naming convention to create the URL to download it.

## Download the snapshot

We can now build the URL to the snapshot in the following manner:

```bash
{QDRANT_URL}/collections/{collection_name}/snapshots/{snapshot_name}
```

In our case, since we are using a local Docker container, our `collection_name = "LAION-5B"`, and `snapshot_name = "LAION-5B-1217055918586176-2023-07-04-11-51-24.snapshot"`,
the snapshot might be downloaded using the following URL:

```bash
http://localhost:6333/collections/LAION-5B/snapshots/LAION-5B-1217055918586176-2023-07-04-11-51-24.snapshot
```


